{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Case Study 4.1 - Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study Description: Building your own recommendation system for movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these cells to install all the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise (from surprise)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fc/cd4210b247d1dca421c25994740cbbf03c5e980e31881f10eaddf45fdab0/scikit-surprise-1.0.6.tar.gz (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 500kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise) (0.11)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise) (1.14.3)\n",
      "Collecting scipy>=1.0.0 (from scikit-surprise->surprise)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 31.2MB 54kB/s eta 0:00:011  4% |█▋                              | 1.5MB 24.6MB/s eta 0:00:02    24% |███████▊                        | 7.5MB 25.4MB/s eta 0:00:01    25% |████████▎                       | 8.0MB 11.8MB/s eta 0:00:02    57% |██████████████████▌             | 18.0MB 7.6MB/s eta 0:00:02    59% |███████████████████             | 18.6MB 7.4MB/s eta 0:00:02    65% |█████████████████████▏          | 20.6MB 6.8MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise) (1.11.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Running setup.py bdist_wheel for scikit-surprise ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/ec/c0/55/3a28eab06b53c220015063ebbdb81213cd3dcbb72c088251ec\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scipy, scikit-surprise, surprise\n",
      "  Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "Successfully installed scikit-surprise-1.0.6 scipy-1.1.0 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you must press **Kernel > Restart.** This allows the installation to take effect. Once you see the blue **Connected/Kernel ready** button in the top right, you are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "from surprise import Dataset, SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\n",
    "from surprise.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`**Dataset.load_builtin**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.Dataset.load_builtin) function to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here to load the data...\n",
    "data=Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to get a sense of what the data looks like. Please create a histogram of all the ratings we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f59333d8a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAE69JREFUeJzt3X+s3fV93/HnK+ZH6bLETrhhyLZq1FlrSLY6ya2xlGmiSWcMTDOVEgk2BStidReBlmrVFKfTRPMDifzRIiElSO5wYqo2hNFGeIlT16JJq2wJcElcwFDkW8KCC4GbmfBj6Ygg7/1xPh5H/hz7nnuv8bnEz4f01fme9/fz/d739yDu657v93OOU1VIkjTsDZNuQJK0/BgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6pwx6QYW69xzz61169ZNug1Jel25//77f1hVU/ONe92Gw7p165iZmZl0G5L0upLkf40zbt7LSkl+Lsm9Sf46ycEkn2j1LyT5XpIDbdnQ6klyc5LZJA8keffQsbYlOdSWbUP19yR5sO1zc5Is/JQlSSfLOO8cXgLeV1UvJjkT+GaSr7Vt/6mq7jxm/KXA+rZcBNwCXJTkLcD1wDRQwP1J9lTVs23MduDbwF5gC/A1JEkTMe87hxp4sT09sy0n+irXrcBtbb9vAyuTnA9cAuyvqiMtEPYDW9q2N1XVt2rwFbG3AVcs4ZwkSUs01mylJCuSHACeYfAL/p626YZ26eimJGe32mrgiaHdD7faieqHR9RH9bE9yUySmbm5uXFalyQtwljhUFWvVNUGYA2wMck7gY8DvwT8CvAW4GNt+Kj7BbWI+qg+dlbVdFVNT03Ne7NdkrRIC/qcQ1X9CPgGsKWqnmqXjl4CPg9sbMMOA2uHdlsDPDlPfc2IuiRpQsaZrTSVZGVbPwf4NeBv2r0C2syiK4CH2i57gKvbrKVNwHNV9RSwD9icZFWSVcBmYF/b9kKSTe1YVwN3ndzTlCQtxDizlc4HdidZwSBM7qiqryT5iyRTDC4LHQD+fRu/F7gMmAV+DHwYoKqOJPkUcF8b98mqOtLWPwJ8ATiHwSwlZypJ0gTl9fpvSE9PT5cfgpNeO+t2fHXSLQDw+I2XT7qFnylJ7q+q6fnG+d1KkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqTOvOGQ5OeS3Jvkr5McTPKJVr8gyT1JDiX5UpKzWv3s9ny2bV83dKyPt/qjSS4Zqm9ptdkkO07+aUqSFmKcdw4vAe+rql8GNgBbkmwCPgPcVFXrgWeBa9r4a4Bnq+ofAze1cSS5ELgSeAewBfhckhVJVgCfBS4FLgSuamMlSRMybzjUwIvt6ZltKeB9wJ2tvhu4oq1vbc9p29+fJK1+e1W9VFXfA2aBjW2ZrarHquonwO1trCRpQsa659D+wj8APAPsB/4W+FFVvdyGHAZWt/XVwBMAbftzwFuH68fsc7y6JGlCxgqHqnqlqjYAaxj8pf/2UcPaY46zbaH1TpLtSWaSzMzNzc3fuCRpURY0W6mqfgR8A9gErExyRtu0BniyrR8G1gK07W8GjgzXj9nnePVRP39nVU1X1fTU1NRCWpckLcA4s5Wmkqxs6+cAvwY8Anwd+EAbtg24q63vac9p2/+iqqrVr2yzmS4A1gP3AvcB69vsp7MY3LTeczJOTpK0OGfMP4Tzgd1tVtEbgDuq6itJHgZuT/Jp4LvArW38rcAfJpll8I7hSoCqOpjkDuBh4GXg2qp6BSDJdcA+YAWwq6oOnrQzlCQt2LzhUFUPAO8aUX+Mwf2HY+v/F/jgcY51A3DDiPpeYO8Y/UqSTgE/IS1J6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqTOON/KKp021u346qRbAODxGy+fdAs6zfnOQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUmTcckqxN8vUkjyQ5mOSjrf67Sf4uyYG2XDa0z8eTzCZ5NMklQ/UtrTabZMdQ/YIk9yQ5lORLSc462ScqSRrfOO8cXgZ+u6reDmwCrk1yYdt2U1VtaMtegLbtSuAdwBbgc0lWJFkBfBa4FLgQuGroOJ9px1oPPAtcc5LOT5K0CPOGQ1U9VVXfaesvAI8Aq0+wy1bg9qp6qaq+B8wCG9syW1WPVdVPgNuBrUkCvA+4s+2/G7hisSckSVq6Bd1zSLIOeBdwTytdl+SBJLuSrGq11cATQ7sdbrXj1d8K/KiqXj6mPurnb08yk2Rmbm5uIa1LkhZg7HBI8kbgT4DfqqrngVuAXwQ2AE8Bv3d06IjdaxH1vli1s6qmq2p6ampq3NYlSQs01ld2JzmTQTD8UVX9KUBVPT20/Q+Ar7Snh4G1Q7uvAZ5s66PqPwRWJjmjvXsYHi9JmoBxZisFuBV4pKp+f6h+/tCwXwceaut7gCuTnJ3kAmA9cC9wH7C+zUw6i8FN6z1VVcDXgQ+0/bcBdy3ttCRJSzHOO4f3Ah8CHkxyoNV+h8Fsow0MLgE9DvwmQFUdTHIH8DCDmU7XVtUrAEmuA/YBK4BdVXWwHe9jwO1JPg18l0EYSZImZN5wqKpvMvq+wN4T7HMDcMOI+t5R+1XVYwxmM0mSlgE/IS1J6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6ozzz4RK0mlt3Y6vTroFAB6/8fJT9rN85yBJ6hgOkqSO4SBJ6swbDknWJvl6kkeSHEzy0VZ/S5L9SQ61x1WtniQ3J5lN8kCSdw8da1sbfyjJtqH6e5I82Pa5OUlei5OVJI1nnHcOLwO/XVVvBzYB1ya5ENgB3F1V64G723OAS4H1bdkO3AKDMAGuBy4CNgLXHw2UNmb70H5bln5qkqTFmjccquqpqvpOW38BeARYDWwFdrdhu4Er2vpW4LYa+DawMsn5wCXA/qo6UlXPAvuBLW3bm6rqW1VVwG1Dx5IkTcCC7jkkWQe8C7gHOK+qnoJBgABva8NWA08M7Xa41U5UPzyiPurnb08yk2Rmbm5uIa1LkhZg7HBI8kbgT4DfqqrnTzR0RK0WUe+LVTurarqqpqempuZrWZK0SGOFQ5IzGQTDH1XVn7by0+2SEO3xmVY/DKwd2n0N8OQ89TUj6pKkCRlntlKAW4FHqur3hzbtAY7OONoG3DVUv7rNWtoEPNcuO+0DNidZ1W5Ebwb2tW0vJNnUftbVQ8eSJE3AOF+f8V7gQ8CDSQ602u8ANwJ3JLkG+D7wwbZtL3AZMAv8GPgwQFUdSfIp4L427pNVdaStfwT4AnAO8LW2SJImZN5wqKpvMvq+AMD7R4wv4NrjHGsXsGtEfQZ453y9SJJODT8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqzBsOSXYleSbJQ0O1303yd0kOtOWyoW0fTzKb5NEklwzVt7TabJIdQ/ULktyT5FCSLyU562SeoCRp4cZ55/AFYMuI+k1VtaEtewGSXAhcCbyj7fO5JCuSrAA+C1wKXAhc1cYCfKYdaz3wLHDNUk5IkrR084ZDVf0VcGTM420Fbq+ql6rqe8AssLEts1X1WFX9BLgd2JokwPuAO9v+u4ErFngOkqSTbCn3HK5L8kC77LSq1VYDTwyNOdxqx6u/FfhRVb18TF2SNEGLDYdbgF8ENgBPAb/X6hkxthZRHynJ9iQzSWbm5uYW1rEkaWyLCoeqerqqXqmqnwJ/wOCyEQz+8l87NHQN8OQJ6j8EViY545j68X7uzqqarqrpqampxbQuSRrDosIhyflDT38dODqTaQ9wZZKzk1wArAfuBe4D1reZSWcxuGm9p6oK+Drwgbb/NuCuxfQkSTp5zphvQJIvAhcD5yY5DFwPXJxkA4NLQI8DvwlQVQeT3AE8DLwMXFtVr7TjXAfsA1YAu6rqYPsRHwNuT/Jp4LvArSft7CRJizJvOFTVVSPKx/0FXlU3ADeMqO8F9o6oP8arl6UkScuAn5CWJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHXm/Zfg9LNv3Y6vTroFAB6/8fJJtyCp8Z2DJKljOEiSOoaDJKljOEiSOvOGQ5JdSZ5J8tBQ7S1J9ic51B5XtXqS3JxkNskDSd49tM+2Nv5Qkm1D9fckebDtc3OSnOyTlCQtzDjvHL4AbDmmtgO4u6rWA3e35wCXAuvbsh24BQZhAlwPXARsBK4/GihtzPah/Y79WZKkU2zecKiqvwKOHFPeCuxu67uBK4bqt9XAt4GVSc4HLgH2V9WRqnoW2A9sadveVFXfqqoCbhs6liRpQhZ7z+G8qnoKoD2+rdVXA08MjTvcaieqHx5RHynJ9iQzSWbm5uYW2bokaT4n+4b0qPsFtYj6SFW1s6qmq2p6ampqkS1Kkuaz2HB4ul0Soj0+0+qHgbVD49YAT85TXzOiLkmaoMWGwx7g6IyjbcBdQ/Wr26ylTcBz7bLTPmBzklXtRvRmYF/b9kKSTW2W0tVDx5IkTci8362U5IvAxcC5SQ4zmHV0I3BHkmuA7wMfbMP3ApcBs8CPgQ8DVNWRJJ8C7mvjPllVR29yf4TBjKhzgK+1RZI0QfOGQ1VddZxN7x8xtoBrj3OcXcCuEfUZ4J3z9SFJOnX8hLQkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqTPvvwT3s2rdjq9OugUAHr/x8km3IEkd3zlIkjqGgySpYzhIkjpLCockjyd5MMmBJDOt9pYk+5Mcao+rWj1Jbk4ym+SBJO8eOs62Nv5Qkm1LOyVJ0lKdjHcOv1pVG6pquj3fAdxdVeuBu9tzgEuB9W3ZDtwCgzABrgcuAjYC1x8NFEnSZLwWl5W2Arvb+m7giqH6bTXwbWBlkvOBS4D9VXWkqp4F9gNbXoO+JEljWmo4FPDnSe5Psr3VzquqpwDa49tafTXwxNC+h1vtePVOku1JZpLMzM3NLbF1SdLxLPVzDu+tqieTvA3Yn+RvTjA2I2p1gnpfrNoJ7ASYnp4eOUaStHRLeudQVU+2x2eALzO4Z/B0u1xEe3ymDT8MrB3afQ3w5AnqkqQJWXQ4JPkHSf7h0XVgM/AQsAc4OuNoG3BXW98DXN1mLW0CnmuXnfYBm5OsajeiN7eaJGlClnJZ6Tzgy0mOHuePq+rPktwH3JHkGuD7wAfb+L3AZcAs8GPgwwBVdSTJp4D72rhPVtWRJfQlSVqiRYdDVT0G/PKI+v8G3j+iXsC1xznWLmDXYnuRJJ1cfkJaktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktRZNuGQZEuSR5PMJtkx6X4k6XS2LMIhyQrgs8ClwIXAVUkunGxXknT6WhbhAGwEZqvqsar6CXA7sHXCPUnSaStVNekeSPIBYEtV/bv2/EPARVV13THjtgPb29N/Ajx6ShvtnQv8cMI9LBe+Fq/ytXiVr8Wrlstr8QtVNTXfoDNORSdjyIhal1pVtRPY+dq3M54kM1U1Pek+lgNfi1f5WrzK1+JVr7fXYrlcVjoMrB16vgZ4ckK9SNJpb7mEw33A+iQXJDkLuBLYM+GeJOm0tSwuK1XVy0muA/YBK4BdVXVwwm2NY9lc4loGfC1e5WvxKl+LV72uXotlcUNakrS8LJfLSpKkZcRwkCR1DAdJUsdwkJYoycYkv9LWL0zyH5NcNum+Ji3JbZPuQYu3LGYr6fUnyS8Bq4F7qurFofqWqvqzyXV2aiW5nsF3gp2RZD9wEfANYEeSd1XVDZPs71RJcuzU8wC/mmQlQFX961Pf1fKR5J8z+Jqgh6rqzyfdzzicrXQSJPlwVX1+0n2cKkn+A3At8AiwAfhoVd3Vtn2nqt49yf5OpSQPMngNzgZ+AKypqueTnMMgOP/ZRBs8RZJ8B3gY+K8Mvt0gwBcZfGaJqvrLyXV36iW5t6o2tvXfYPD/y5eBzcB/r6obJ9nfOLysdHJ8YtINnGK/Abynqq4ALgb+S5KPtm2jvgrlZ9nLVfVKVf0Y+Nuqeh6gqv4e+OlkWzulpoH7gf8MPFdV3wD+vqr+8nQLhubMofXtwL+sqk8wCId/O5mWFsbLSmNK8sDxNgHnncpeloEVRy8lVdXjSS4G7kzyC5x+4fCTJD/fwuE9R4tJ3sxpFA5V9VPgpiT/rT0+zen9++UNSVYx+AM8VTUHUFX/J8nLk21tPKfzf7yFOg+4BHj2mHqA/3nq25moHyTZUFUHAKrqxST/CtgF/NPJtnbK/Yuqegn+/y/Io84Etk2mpcmpqsPAB5NcDjw/6X4m6M0M3kkFqCT/qKp+kOSNvE7+gPKew5iS3Ap8vqq+OWLbH1fVv5lAWxORZA2Dyyk/GLHtvVX1PybQlrTsJfl54Lyq+t6ke5mP4SBJ6nhDWpLUMRwkSR3DQZLUMRwkSZ3/BzwD8xW02BvPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5933669320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here to create a ratings histogram...\n",
    "rf=data.ratings_file\n",
    "col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "raw_data = pd.read_table(rf,names=col_names)\n",
    "raw_data.head(5)\n",
    "raw_data['rating'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    34174\n",
       "3    27145\n",
       "5    21201\n",
       "2    11370\n",
       "1     6110\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Random\n",
    "\n",
    "\n",
    "##### We want to first get a baseline value for our model. That can be best done with random model as this algorithm is not personalized to the desires of any users - we just assign them movie ratings based on the initial distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to first get a baseline value for our model. That can be best done with random model as this algorithm is not personalized to the desires of any users - we just assign them movie ratings based on the initial distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using NormalPredictor() class\n",
    "model=NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5230  1.5143  1.5237  1.5265  1.5187  1.5212  0.0043  \n",
      "Fit time          0.47    0.67    0.65    0.50    0.52    0.56    0.08    \n",
      "Test time         1.06    0.83    0.97    0.65    0.65    0.83    0.17    \n"
     ]
    }
   ],
   "source": [
    "# Train on data using cross-validation with k=5 folds, measuring the RMSE\n",
    "model_random_results = cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "# See the cross_validate function that we have imported above\n",
    "# http://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.validation.cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: User-Based Collaborative Filtering\n",
    "\n",
    "##### User-Based Collaborative Filtering model will use the user-user defined notion of similarity to implement collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using KNNBasic() class\n",
    "sim_options={'name':'cosine','user_based':True}\n",
    "model_KNN_user_based=KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# See the sim_options parameter to determine the user/item similarity calculation of the model\n",
    "# http://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0071  1.0141  1.0189  1.0230  1.0232  1.0173  0.0061  \n",
      "Fit time          4.99    5.04    5.78    5.71    5.31    5.37    0.33    \n",
      "Test time         16.88   17.86   20.32   18.16   17.23   18.09   1.20    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_KNN_user_based_results = cross_validate(model_KNN_user_based, data, measures=['RMSE'], cv=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Item-Based Collaborative Filtering\n",
    "\n",
    "##### This model will use item-item defined notion of similarity to once again implement collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using KNNBasic() class\n",
    "# Make sure you change the sim_options parameter from above\n",
    "sim_options={'name':'cosine','user_based':False}\n",
    "model_KNN_item_based=KNNBasic(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0216  1.0271  1.0184  1.0218  1.0409  1.0259  0.0080  \n",
      "Fit time          8.65    9.01    7.23    7.46    8.76    8.22    0.73    \n",
      "Test time         18.57   18.50   17.97   18.36   20.77   18.83   0.99    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_KNN_item_based_results = cross_validate(model_KNN_item_based, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Matrix Factorization\n",
    "##### Our final model for this case study will use the matrix factorization approach with the SVD algorithm to try to predict user’s movie ratings. Here, we try to determine some underlying mathematical structure in the user rating matrix, which can help us predict missing ratings in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using SVD() class\n",
    "model_SVD=SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9292  0.9328  0.9368  0.9418  0.9376  0.9356  0.0043  \n",
      "Fit time          23.29   24.40   23.69   26.45   25.83   24.73   1.22    \n",
      "Test time         0.90    0.84    1.30    1.33    1.25    1.12    0.21    \n"
     ]
    }
   ],
   "source": [
    "# Train using same cross validation code as above\n",
    "model_SVD_results = cross_validate(model_SVD,data,measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall @ `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Here precision and recall is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = dict()\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        current = user_est_true.get(uid, list())\n",
    "        current.append((est, true_r))\n",
    "        user_est_true[uid] = current\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the precision and recall at `k` = 5 and 10 for each of our 4 models. We use 5-fold cross validation again to average the results across the entire dataset.\n",
    "\n",
    "Please note that this will take some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> precision: 0.587\n",
      ">>> reccall  : 0.34\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.583\n",
      ">>> reccall  : 0.342\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.586\n",
      ">>> reccall  : 0.344\n",
      ">>> precision: 0.589\n",
      ">>> reccall  : 0.345\n",
      ">>> precision: 0.583\n",
      ">>> reccall  : 0.425\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.59\n",
      ">>> reccall  : 0.432\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      ">>> precision: 0.586\n",
      ">>> reccall  : 0.438\n",
      ">>> precision: 0.582\n",
      ">>> reccall  : 0.428\n"
     ]
    }
   ],
   "source": [
    "# Use the function above to compute the 16 numerical values requested above\n",
    "K=[5,10]\n",
    "models=[model,model_KNN_user_based,model_KNN_item_based,model_SVD]\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k in K:\n",
    "    for modl in models:\n",
    "        p=[]\n",
    "        r=[]\n",
    "        for train_set,test_set in kf.split(data):\n",
    "            modl.fit(train_set)\n",
    "            predictions=model.test(test_set,verbose=False)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5)\n",
    "            \n",
    "            p.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            r.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "            \n",
    "        print('>>> precision:', round(sum(p) / len(p), 3))\n",
    "        print('>>> reccall  :', round(sum(r) / len(r), 3))\n",
    "        \n",
    "\n",
    "\n",
    "# See the test() function to get the predictions input to the function\n",
    "# http://surprise.readthedocs.io/en/stable/algobase.html#surprise.prediction_algorithms.algo_base.AlgoBase.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Top-`n` Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see what some of the actual movie ratings are for particular users, as outputs of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = dict()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        current = top_n.get(uid, [])\n",
    "        current.append((iid, est))\n",
    "        top_n[uid] = current\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we call this function on each of our models, first training on **all** the data we have available, then predicting on the remaining, missing data. We use `n`=5 here, but you can pick any reasonable value of `n` you would like.\n",
    "\n",
    "This may take some time to compute, so be patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use [`**Dataset.build_full_trainset**`](http://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.DatasetAutoFolds.build_full_trainset) to get the full trainset from the data. Then call [`**Trainset.build_anti_testset**`](http://surprise.readthedocs.io/en/stable/trainset.html#surprise.Trainset.build_anti_testset) to get the testset out. Finally, `fit` on the trainset, `test` on the testset, then pass that result to our `get_top_n` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7f5934a6cc88>, 196: [('16', 5), ('979', 5), ('526', 5), ('21', 5), ('264', 5)]\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f593b7c7e10>, 196: [('1189', 5), ('1500', 5), ('814', 5), ('1536', 5), ('1293', 5)]\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "model: <surprise.prediction_algorithms.knns.KNNBasic object at 0x7f5934a6cda0>, 196: [('1309', 4.5), ('1310', 4.5), ('1676', 4.25), ('1675', 4.25), ('1593', 4.090909090909091)]\n",
      "model: <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7f5934a6c978>, 196: [('114', 4.702587518165476), ('603', 4.4913732760844844), ('357', 4.423351836916481), ('64', 4.423188384608302), ('169', 4.421457082682124)]\n"
     ]
    }
   ],
   "source": [
    "# Use the function and hints above to give the top-n predictions for a given user, for a reasonable value of n\n",
    "for model in models:\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    top_n = get_top_n(predictions, n=5)\n",
    "    # Print the first one\n",
    "    user = list(top_n.keys())[0]\n",
    "    print(f'model: {model}, {user}: {top_n[user]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now, make sure you check out the **Conclusion** section of the [instruction manual](https://courses.edx.org/asset-v1:MITxPRO+DSx+2T2018+type@asset+block@4.1_instruction_manual.html) to wrap up this case study properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
